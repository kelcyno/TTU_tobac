{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import xarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#from six.moves import urllib\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib  as mpl \n",
    "import pickle\n",
    "import pyart\n",
    "from datetime import datetime\n",
    "import math\n",
    "from pandas.core.common import flatten\n",
    "%matplotlib inline\n",
    "#%matplotlib widget\n",
    "\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tobac itself:\n",
    "import tobac\n",
    "from tobac.merge_split import standardize_track_dataset, compress_all, merge_split\n",
    "#Disable a couple of warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2aed2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def qc_reflectivity2(dataset,rhv, ref = None):\n",
    "    for i in range(len(dataset['time'])):\n",
    "        refl = np.array(dataset['reflectivity'][i, :, :, :])\n",
    "        refl[np.array(dataset['cross_correlation_ratio'][i, :, :, :]) < rhv] = -999 #0\n",
    "        #refl[np.array(dataset['correlation_coefficient'][i, :, :, :]) < rhv] = -999 #0\n",
    "        if ref:\n",
    "            refl[refl < ref] = np.nan #-999 #0\n",
    "        dataset['reflectivity'][i, :, :, :] = refl\n",
    "        max_refl = dataset['reflectivity'].max(axis=1,skipna=True)\n",
    "        #p = np.where(max_refl)\n",
    "        #dataset = dataset.assign(max_reflectivity=lambda dataset:max_refl)\n",
    "    return max_refl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/kelcy/DATA/20220604/KHGX20220604_*_V06_grid.nc\"\n",
    "data = xarray.open_mfdataset(path, engine = 'netcdf4')\n",
    "data['time'].encoding['units']=\"seconds since 2000-01-01 00:00:00\"\n",
    "rho = 0.90\n",
    "ref =  10\n",
    "maxrefl = qc_reflectivity2(data,rho,ref = ref)\n",
    "\n",
    "maxrefl.to_netcdf(os.path.join(savedir,'20220604_maxrefl.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up directory to save output and plots:\n",
    "savedir='tobac_Save'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "plot_dir=\"tobac_Plot\"\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc4e56",
   "metadata": {},
   "source": [
    "#Feature detection:\n",
    "#Feature detection is perfomed based on surface precipitation field and a range of thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f25e17",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Dictionary containing keyword options (could also be directly given to the function)\n",
    "parameters_features={}\n",
    "parameters_features['position_threshold']='weighted_diff'\n",
    "parameters_features['sigma_threshold']= 1.0 #0.5 is the default\n",
    "parameters_features['threshold']= 15 \n",
    "#parameters_features['min_num']=0\n",
    "#parameters_features['min_distance']=5 #0 #15\n",
    "#parameters_features['n_erosion_threshold']=0\n",
    "#parameters_features['n_min_threshold']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed406fe7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Dt, DXY\n",
    "datetimes = data['time']\n",
    "timedeltas = [(datetimes[i-1]-datetimes[i]).astype('timedelta64[m]') for i in range(1, len(datetimes))]\n",
    "print(len(timedeltas))\n",
    "average_timedelta = sum(timedeltas) / len(timedeltas)\n",
    "dt = np.abs(np.array(average_timedelta)).astype('timedelta64[m]').astype(int)\n",
    "\n",
    "\n",
    "deltax = [data['x'][i-1]-data['x'][i] for i in range(1, len(data['x']))]\n",
    "dxy = np.abs(np.mean(deltax).astype(int))/1000\n",
    "\n",
    "\n",
    "print(dxy,dt)\n",
    "# dxy = 0.5\n",
    "# dt = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b97c5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxrefl_iris=maxrefl.to_iris()\n",
    "# Feature detection based on based on surface precipitation field and a range of thresholds\n",
    "print('starting feature detection based on multiple thresholds')\n",
    "Features_iris=tobac.feature_detection_multithreshold(maxrefl_iris,dxy,**parameters_features)\n",
    "Features=Features_iris.to_xarray()\n",
    "print('feature detection done')\n",
    "Features.to_netcdf(os.path.join(savedir,'Features.nc'))\n",
    "print('features saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da41e2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Dictionary containing keyword arguments for segmentation step:\n",
    "parameters_segmentation={}\n",
    "parameters_segmentation['method']='watershed'\n",
    "parameters_segmentation['threshold']=15  # mm/h mixing ratio\n",
    "#parameters_segmentation['ISO_dilate']=10 #this is the size \n",
    "#parameters_segmentation['features']\n",
    "#parameters_segmentation['field']\n",
    "#parameters_segmentation['dxy']\n",
    "#parameters_segmentation['target']\n",
    "#parameters_segmentation['level']\n",
    "#parameters_segmentation['method']\n",
    "#parameters_segmentation['max_distance']\n",
    "#Maximum distance from a marker allowed to be classified as\n",
    "        #belonging to that cell. Default is None.\n",
    "#parameters_segmentation['vertical_coord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2f460",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "Features_df=Features.to_dataframe()\n",
    "\n",
    "# Perform Segmentation and save resulting mask to NetCDF file:\n",
    "print('Starting segmentation based on reflectivity')\n",
    "Mask_iris,Features_Precip =tobac.segmentation.segmentation(Features_df,maxrefl_iris,dxy,**parameters_segmentation)\n",
    "#Mask,Features_Precip=tobac.themes.tobac_v1.segmentation(Features,maxrefl,dxy,**parameters_segmentation)\n",
    "Features_Precip=Features_Precip.to_xarray()\n",
    "Mask=xarray.DataArray.from_iris(Mask_iris)\n",
    "Mask = Mask.to_dataset()\n",
    "\n",
    "\n",
    "#Mask,Features_Precip=segmentation(Features,maxrefl,dxy,**parameters_segmentation)\n",
    "print('segmentation based on reflectivity performed, start saving results to files')\n",
    "Mask.to_netcdf(os.path.join(savedir,'Mask_Segmentation_refl.nc'))                \n",
    "Features_Precip.to_netcdf(os.path.join(savedir,'Features_Precip.nc'))\n",
    "print('segmentation reflectivity performed and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30758dd",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "areas = np.zeros([(len(Features['index'])+1)])\n",
    "#Mask = Mask.to_dataset()\n",
    "frame_features = Features.groupby('frame')\n",
    "\n",
    "for frame_i, features_i in frame_features: \n",
    "    mask_i = Mask['segmentation_mask'][frame_i,:,:].values\n",
    "    for i in np.unique(mask_i):\n",
    "        feature_area_i = np.where(mask_i == i)\n",
    "        areas[i] = len(feature_area_i[0])\n",
    "\n",
    "#areas = large_list[1:,1]\n",
    "#var = Features['feature'].copy(data = areas[1:])\n",
    "#var = var.rename(\"areas\")\n",
    "#var = Features_Precip['feature'].copy(data = areas[1:])\n",
    "var = Features['feature'].copy(data = areas[1:])\n",
    "var = var.rename(\"areas\")\n",
    "Features_Precip = xarray.merge([Features_Precip,var], compat = 'override')\n",
    "Features = xarray.merge([Features,var], compat = 'override')\n",
    "Features_Precip.to_netcdf(os.path.join(savedir, 'Features_Precip.nc'))\n",
    "Features.to_netcdf(os.path.join(savedir,'Features.nc'))\n",
    "Mask = Mask.to_array()\n",
    "Features_df=Features.to_dataframe()\n",
    "print('features saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbed5f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Dictionary containing keyword arguments for the linking step:\n",
    "parameters_linking={}\n",
    "parameters_linking['stubs'] = 3#5\n",
    "parameters_linking['method_linking']='predict'\n",
    "parameters_linking['adaptive_stop']=0.2\n",
    "parameters_linking['adaptive_step']=0.95\n",
    "parameters_linking['extrapolate']=2 #was 1 - the number of frames to extrapolate to\n",
    "parameters_linking['order']=2 #Order of polynomial for extrapolating\n",
    "parameters_linking['subnetwork_size']=100 #50 #100\n",
    "parameters_linking['memory']= 2\n",
    "#parameters_linking['time_cell_min']=1\n",
    "parameters_linking['v_max']=1.0 #2.0#.5\n",
    "parameters_linking['d_min']= None #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ec558",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Perform trajectory linking using trackpy and save the resulting DataFrame:\n",
    "\n",
    "#Track=tobac.themes.tobac_v1.linking_trackpy(Features,Mask,dt=dt,dxy=dxy,**parameters_linking)\n",
    "Features_df=Features.to_dataframe()\n",
    "Track=tobac.linking_trackpy(Features_df,Mask_iris,dt=dt,dxy=dxy,**parameters_linking)\n",
    "Track = Track.to_xarray()\n",
    "Track.to_netcdf(os.path.join(savedir,'Track.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c0b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Track = xarray.open_dataset(savedir+\"/Track.nc\")\n",
    "Features = xarray.open_dataset(savedir+\"/Features.nc\")\n",
    "refl_mask = xarray.open_dataset(savedir+\"/Mask_Segmentation_refl.nc\")\n",
    "refl_features = xarray.open_dataset(savedir+\"/Features_Precip.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e07a6d-2d60-4658-87b3-fe9e1e9a21c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "d, track_id = merge_split(Track,distance = 20000.)\n",
    "ds = standardize_track_dataset(Track, refl_mask, data['ProjectionCoordinateSystem'])\n",
    "# both_ds = xr.combine_by_coords((ds,d), compat='override')\n",
    "both_ds = xr.merge([ds, d],compat ='override')\n",
    "both_ds = compress_all(both_ds)\n",
    "both_ds.to_netcdf(os.path.join(savedir,'Track_features_merges.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354479a",
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame = 33\n",
    "\n",
    "#\n",
    "isolated_min = 0.5\n",
    "show_tracks = True\n",
    "ref_levels = [5,10,15,20,25,30,35,40,45,50,55,60,65,70,75]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "refl = maxrefl[frame,:,:] #data['max_reflectivity'][id,:,:]\n",
    "fig.suptitle(str(maxrefl['time'][frame].data)[:-10])# + 'rhohv = '+str(rho) + ', ref > ' + str(ref))\n",
    "y_mesh,x_mesh = np.meshgrid(maxrefl['x'],maxrefl['y'])\n",
    "    \n",
    "refplt = ax.contourf(y_mesh,x_mesh, refl, extend = 'max',levels = ref_levels,cmap='pyart_LangRainbow12',origin = 'lower', vmin=-24, vmax=72)#,extent = [0,-10000,-20000,-10000])\n",
    "fig.colorbar(refplt,fraction=0.046, pad=0.04)\n",
    "i = np.where(refl_mask['segmentation_mask'][frame,:,:] > 0)\n",
    "#print(str(len(np.unique(refl_mask['segmentation_mask'][frame,:,:]))) + ' unique mask shapes')\n",
    "y, x = y_mesh[i[0],i[1]],x_mesh[i[0],i[1]]\n",
    "imcell2 = ax.scatter(y,x,s = 0.1,c = 'gray', marker = '.',alpha = 0.5)\n",
    "# plt.xlim([-50000,50000])\n",
    "# plt.ylim([-100000,0])\n",
    "# plt.xlim([-250000,-150000])\n",
    "# plt.ylim([-140000,-40000])\n",
    "\n",
    "# iso = 0\n",
    "# not_iso = 0\n",
    "# for i in np.unique(refl_mask['segmentation_mask'][frame,:,:]): #True means there's something around the feature\n",
    "#     if i == 0:\n",
    "#         not_iso += 1\n",
    "#         continue\n",
    "#     else:\n",
    "#         if refl_features['num_objects'][int(i-1)].data == 2:\n",
    "#             iso += 1\n",
    "#     #if refl_features['isolated'][int(i-1)].data == False: #referencing by index count starts at 0, referencing by finding or where count is true.\n",
    "#         #i -= 1\n",
    "#             p = np.where(refl_mask['segmentation_mask'][frame,:,:] == i)\n",
    "#             y, x = y_mesh[p[0],p[1]],x_mesh[p[0],p[1]]\n",
    "#             imcell2 = ax.scatter(y,x,s = 0.1,c = 'purple', marker = '.',alpha = 0.5)\n",
    "#         if refl_features['num_objects'][int(i-1)].data > 2:\n",
    "#             not_iso += 1\n",
    "\n",
    "# print(not_iso)\n",
    "# print(iso)\n",
    "# print(len(np.unique(refl_mask['segmentation_mask'][frame,:,:]))-1)\n",
    "\n",
    "for i in np.unique(Track['cell']):\n",
    "    #print(i)\n",
    "    if math.isfinite(i):\n",
    "        track_i = np.where(Track['cell'] == i)\n",
    "        \n",
    "        if np.any(Track['frame'][track_i] == frame):\n",
    "            ax.plot(Track['projection_x_coordinate'][track_i], Track['projection_y_coordinate'][track_i], '-.',color='r')\n",
    "            #ax.plot(Track['x'][track_i], Track['y'][track_i], '-.',color='r')\n",
    "            ax.text(Track['projection_x_coordinate'][track_i][-1],Track['projection_y_coordinate'][track_i][-1], f'{int(i)}',fontsize = 'small',rotation = 'vertical')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# #     for i in [743]:           \n",
    "# for i in track_id[236]: #np.unique(Track['cell']):634,943\n",
    "# #         if i < 1299:\n",
    "# #             continue\n",
    "#         track_i = np.where(Track['cell'] == i)\n",
    "#     #ax.plot(Track['x'][track_i], Track['y'][track_i], '-.',color='b')\n",
    "#     #ax.text(Track['x'][track_i][-1],Track['y'][track_i][-1], f'Tr {int(i)}')\n",
    "#         ax.plot(Track['projection_x_coordinate'][track_i], Track['projection_y_coordinate'][track_i], '-.',color='b')\n",
    "#         #ax.text(Track['projection_x_coordinate'][track_i][3],Track['projection_y_coordinate'][track_i][3], f'{int(i)}',\n",
    "#                 #fontsize = 'small',rotation = 'vertical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdfe13-2b28-4dd7-bf32-191acb1b53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n",
    "from scipy import ndimage\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    import pyproj\n",
    "    _PYPROJ_AVAILABLE = True\n",
    "except ImportError:\n",
    "    _PYPROJ_AVAILABLE = False\n",
    "\n",
    "def cartesian_to_geographic_aeqd(x, y, lon_0, lat_0, R=6370997.):\n",
    "    \"\"\"\n",
    "    Azimuthal equidistant Cartesian to geographic coordinate transform.\n",
    "\n",
    "    Transform a set of Cartesian/Cartographic coordinates (x, y) to\n",
    "    geographic coordinate system (lat, lon) using a azimuthal equidistant\n",
    "    map projection [1]_.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        lat = \\\\arcsin(\\\\cos(c) * \\\\sin(lat_0) +\n",
    "                       (y * \\\\sin(c) * \\\\cos(lat_0) / \\\\rho))\n",
    "\n",
    "        lon = lon_0 + \\\\arctan2(\n",
    "            x * \\\\sin(c),\n",
    "            \\\\rho * \\\\cos(lat_0) * \\\\cos(c) - y * \\\\sin(lat_0) * \\\\sin(c))\n",
    "\n",
    "        \\\\rho = \\\\sqrt(x^2 + y^2)\n",
    "\n",
    "        c = \\\\rho / R\n",
    "\n",
    "    Where x, y are the Cartesian position from the center of projection;\n",
    "    lat, lon the corresponding latitude and longitude; lat_0, lon_0 are the\n",
    "    latitude and longitude of the center of the projection; R is the radius of\n",
    "    the earth (defaults to ~6371 km). lon is adjusted to be between -180 and\n",
    "    180.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like\n",
    "        Cartesian coordinates in the same units as R, typically meters.\n",
    "    lon_0, lat_0 : float\n",
    "        Longitude and latitude, in degrees, of the center of the projection.\n",
    "    R : float, optional\n",
    "        Earth radius in the same units as x and y. The default value is in\n",
    "        units of meters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lon, lat : array\n",
    "        Longitude and latitude of Cartesian coordinates in degrees.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Snyder, J. P. Map Projections--A Working Manual. U. S. Geological\n",
    "        Survey Professional Paper 1395, 1987, pp. 191-202.\n",
    "\n",
    "    \"\"\"\n",
    "    x = np.atleast_1d(np.asarray(x))\n",
    "    y = np.atleast_1d(np.asarray(y))\n",
    "\n",
    "    lat_0_rad = np.deg2rad(lat_0)\n",
    "    lon_0_rad = np.deg2rad(lon_0)\n",
    "\n",
    "    rho = np.sqrt(x*x + y*y)\n",
    "    c = rho / R\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        # division by zero may occur here but is properly addressed below so\n",
    "        # the warnings can be ignored\n",
    "        warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "        lat_rad = np.arcsin(np.cos(c) * np.sin(lat_0_rad) +\n",
    "                            y * np.sin(c) * np.cos(lat_0_rad) / rho)\n",
    "    lat_deg = np.rad2deg(lat_rad)\n",
    "    # fix cases where the distance from the center of the projection is zero\n",
    "    lat_deg[rho == 0] = lat_0\n",
    "\n",
    "    x1 = x * np.sin(c)\n",
    "    x2 = rho*np.cos(lat_0_rad)*np.cos(c) - y*np.sin(lat_0_rad)*np.sin(c)\n",
    "    lon_rad = lon_0_rad + np.arctan2(x1, x2)\n",
    "    lon_deg = np.rad2deg(lon_rad)\n",
    "    # Longitudes should be from -180 to 180 degrees\n",
    "    lon_deg[lon_deg > 180] -= 360.\n",
    "    lon_deg[lon_deg < -180] += 360.\n",
    "\n",
    "    return lon_deg, lat_deg\n",
    "\n",
    "def cartesian_to_geographic(grid_ds):\n",
    "    \"\"\"\n",
    "    Cartesian to Geographic coordinate transform.\n",
    "\n",
    "    Transform a set of Cartesian/Cartographic coordinates (x, y) to a\n",
    "    geographic coordinate system (lat, lon) using pyproj or a build in\n",
    "    Azimuthal equidistant projection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grid_ds: xarray DataSet\n",
    "        Cartesian coordinates in meters unless R is defined in different units\n",
    "        in the projparams parameter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lon, lat : array\n",
    "        Longitude and latitude of the Cartesian coordinates in degrees.\n",
    "\n",
    "    \"\"\"\n",
    "    projparams = grid_ds.ProjectionCoordinateSystem\n",
    "    x = grid_ds.x.values\n",
    "    y = grid_ds.y.values\n",
    "    z = grid_ds.z.values\n",
    "    z, y, x = np.meshgrid(z, y, x, indexing='ij')\n",
    "    if projparams.attrs['grid_mapping_name'] == 'azimuthal_equidistant':\n",
    "        # Use Py-ART's Azimuthal equidistance projection\n",
    "        lat_0 = projparams.attrs['latitude_of_projection_origin']\n",
    "        lon_0 = projparams.attrs['longitude_of_projection_origin']\n",
    "        if 'semi_major_axis' in projparams:\n",
    "            R = projparams.attrs['semi_major_axis']\n",
    "            lon, lat = cartesian_to_geographic_aeqd(x, y, lon_0, lat_0, R)\n",
    "        else:\n",
    "            lon, lat = cartesian_to_geographic_aeqd(x, y, lon_0, lat_0)\n",
    "    else:\n",
    "        # Use pyproj for the projection\n",
    "        # check that pyproj is available\n",
    "        if not _PYPROJ_AVAILABLE:\n",
    "            raise MissingOptionalDependency(\n",
    "                \"PyProj is required to use cartesian_to_geographic \"\n",
    "                \"with a projection other than pyart_aeqd but it is not \"\n",
    "                \"installed\")\n",
    "        proj = pyproj.Proj(projparams)\n",
    "        lon, lat = proj(x, y, inverse=True)\n",
    "    return lon, lat\n",
    "\n",
    "\n",
    "def add_lat_lon_grid(grid_ds):\n",
    "    lon, lat = cartesian_to_geographic(grid_ds)\n",
    "    grid_ds[\"point_latitude\"] = xr.DataArray(lat, dims=[\"z\", \"y\", \"x\"])\n",
    "    grid_ds[\"point_latitude\"].attrs[\"long_name\"] = \"Latitude\"\n",
    "    grid_ds[\"point_latitude\"].attrs[\"units\"] = \"degrees\"\n",
    "    grid_ds[\"point_longitude\"] = xr.DataArray(lon, dims=[\"z\", \"y\", \"x\"])\n",
    "    grid_ds[\"point_longitude\"].attrs[\"long_name\"] = \"Latitude\"\n",
    "    grid_ds[\"point_longitude\"].attrs[\"units\"] = \"degrees\"\n",
    "    return grid_ds\n",
    "\n",
    "def parse_grid_datetime(my_ds):\n",
    "    year = my_ds['time'].dt.year\n",
    "    month = my_ds['time'].dt.month\n",
    "    day = my_ds['time'].dt.day\n",
    "    hour = my_ds['time'].dt.hour\n",
    "    minute = my_ds['time'].dt.minute\n",
    "    second = my_ds['time'].dt.second\n",
    "    return datetime(year=year, month=month, day=day,\n",
    "                    hour=hour, minute=minute, second=second)\n",
    "\n",
    "\n",
    "# def get_vert_projection(grid, thresh=40):\n",
    "#     \"\"\" Returns boolean vertical projection from grid. \"\"\"\n",
    "#     return np.any(grid > thresh, axis=0)\n",
    "\n",
    "\n",
    "# def get_filtered_frame(grid, min_size, thresh):\n",
    "#     \"\"\" Returns a labeled frame from gridded radar data. Smaller objects\n",
    "#     are removed and the rest are labeled. \"\"\"\n",
    "#     if len(grid.shape) == 3:\n",
    "#         echo_height = get_vert_projection(grid, thresh)\n",
    "#     else:\n",
    "#         echo_height = grid > thresh\n",
    "#     labeled_echo = ndimage.label(echo_height)[0]\n",
    "#     frame = clear_small_echoes(labeled_echo, min_size)\n",
    "#     return frame\n",
    "\n",
    "\n",
    "# def clear_small_echoes(label_image, min_size):\n",
    "#     \"\"\" Takes in binary image and clears objects less than min_size. \"\"\"\n",
    "#     flat_image = label_image.flatten()\n",
    "#     flat_image = flat_image[flat_image > 0]\n",
    "#     unique_elements, size_table = np.unique(flat_image, return_counts=True)\n",
    "#     small_objects = unique_elements[size_table < min_size]\n",
    "\n",
    "#     for obj in small_objects:\n",
    "#         label_image[label_image == obj] = 0\n",
    "#     label_image = ndimage.label(label_image)\n",
    "#     return label_image[0]\n",
    "\n",
    "\n",
    "# def get_grid_alt(grid_z, alt_meters=1500):\n",
    "#     \"\"\" Returns z-index closest to alt_meters. \"\"\"\n",
    "#     return np.argmin(np.abs(grid_z - alt_meters))\n",
    "\n",
    "\n",
    "# def extract_grid_data(grid_obj, field, grid_size, params):\n",
    "#     \"\"\" Returns filtered grid frame and raw grid slice at global shift\n",
    "#     altitude. \"\"\"\n",
    "#     min_size = params['MIN_SIZE'] / np.prod(grid_size[1:]/1000)\n",
    "#     masked = grid_obj.variables[field].fillna(0).values\n",
    "#     gs_alt = params['GS_ALT']\n",
    "#     raw = masked[get_grid_alt(grid_obj.z.values, gs_alt), :, :]\n",
    "#     frame = get_filtered_frame(masked, min_size, params['FIELD_THRESH'])\n",
    "#     return raw, frame\n",
    "\n",
    "\n",
    "# def get_grid_size(grid_obj):\n",
    "#     z_len = grid_obj.z.values[-1] - grid_obj.z.values[0]\n",
    "#     x_len = grid_obj.x.values[-1] - grid_obj.x.values[0]\n",
    "#     y_len = grid_obj.y.values[-1] - grid_obj.y.values[0]\n",
    "#     z_size = z_len / (grid_obj.z.values.shape[0] - 1)\n",
    "#     x_size = x_len / (grid_obj.x.values.shape[0] - 1)\n",
    "#     y_size = y_len / (grid_obj.y.values.shape[0] - 1)\n",
    "#     return np.array([z_size, y_size, x_size])\n",
    "\n",
    "\n",
    "# def extract_grid_data_2d(grid_obj, field, params):\n",
    "#     grid_size = np.array(grid_obj[field].values.shape)\n",
    "#     min_size = params['MIN_SIZE']\n",
    "#     masked = grid_obj.variables[field].values\n",
    "#     masked = masked > params['FIELD_THRESH']\n",
    "#     print(np.sum(masked))\n",
    "#     raw = masked\n",
    "#     labeled_echo = ndimage.label(masked)[0]\n",
    "#     frame = clear_small_echoes(labeled_echo, min_size)\n",
    "#     return raw, frame    \n",
    "\n",
    "\n",
    "\n",
    "\"\"\" X-Array based TINT I/O module. \"\"\"\n",
    "\n",
    "import xarray as xr\n",
    "import random\n",
    "import numpy as np\n",
    "import pyproj\n",
    "\n",
    "#from .grid_utils import add_lat_lon_grid\n",
    "from datetime import datetime\n",
    "\n",
    "def load_cfradial_grids(file_list):\n",
    "    ds = xr.open_mfdataset(file_list)\n",
    "    # Check for CF/Radial conventions\n",
    "    if not ds.attrs[\"Conventions\"] == 'CF/Radial instrument_parameters':\n",
    "        ds.close()\n",
    "        raise IOError(\"TINT module is only compatible with CF/Radial files!\")\n",
    "    ds = add_lat_lon_grid(ds)\n",
    "#     ds.attrs[\"cf_tree_order\"] = \"storm_id cell_id\"\n",
    "#     ds.attrs[\"tree_id\"] = \"%d\" % random.randint(a=0, b=65535)\n",
    "#     # Try to detect number of fields (4D arrays)\n",
    "#     nfields = 0\n",
    "#     for keys in ds.variables.keys():\n",
    "#         if(len(ds[keys].dims) == 3):\n",
    "#             nfields += 1\n",
    "\n",
    "#     ds['storm_id'] = ('storm', np.arange(0, nfields, 1))\n",
    "#     ds['storm_id'].attrs[\"child\"] = \"cell\"\n",
    "#     ds['storm_id'].attrs[\"tree_id\"] = ds.attrs[\"tree_id\"]\n",
    "\n",
    "    return ds\n",
    "\n",
    "nc_grid = load_cfradial_grids(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9862e-7747-4c66-8150-c25f35c1a7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc8aa6-e517-492c-bab5-482d02023037",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = []\n",
    "for i in range(len(Track['time'])):\n",
    "    #longitude.append(np.mean(nc_grid['point_longitude'].sel({'x':Track['x'].data[i]},method='nearest').data))       \n",
    "    longitude.append(np.mean(nc_grid['point_longitude'].sel({'x':Track['projection_x_coordinate'].data[i]},method='nearest').data))       \n",
    "\n",
    "\n",
    "    \n",
    "latitude = []\n",
    "for i in range(len(Track['time'])):\n",
    "    #latitude.append(np.mean(nc_grid['point_latitude'].sel({'y':Track['y'].data[i]},method='nearest').data))     \n",
    "    latitude.append(np.mean(nc_grid['point_latitude'].sel({'y':Track['projection_y_coordinate'].data[i]},method='nearest').data))     \n",
    "\n",
    "\n",
    "latitude = np.array(latitude)\n",
    "longitude = np.array(longitude)\n",
    "#Track['latitude'] = latitude\n",
    "#Track['longitude'] = longitude\n",
    "\n",
    "nc_lons = nc_grid['point_longitude'][0,:,:].data\n",
    "nc_lats = nc_grid['point_latitude'][0,:,:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34912312-90f9-409d-9e60-ce23f637c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_grid['ProjectionCoordinateSystem'][0].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754ce72-2b19-4b99-a1c8-a76ecf30deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.close('all')\n",
    "#fig = plt.figure(figsize=(9,9))\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "def time_in_range(start, end, x):\n",
    "    \"\"\"Return true if x is in the range [start, end]\"\"\"\n",
    "    if start <= end:\n",
    "        return start <= x <= end\n",
    "    else:\n",
    "        return start <= x or x <= end\n",
    "    \n",
    "\n",
    "def plot(t_index,xrdata,max_refl,features,mask,track, ncgrid,dbz,lons,lats,nclon,nclat,ind = None):\n",
    "    # Get the data\n",
    "    hsv_ctr_lat, hsv_ctr_lon = 29.4719, -95.0792\n",
    "    \n",
    "    #hsv_ctr_lat, hsv_ctr_lon = 34.5550, -86.0500\n",
    "\n",
    "    #refl = xr_data.values[t_index,:,:]#get_qc_ref(xr_data, t_index)\n",
    "    #refl = max_refl[t_index,:,:] #\n",
    "    refl = max_refl[t_index,:,:]\n",
    "    #refl = get_qc_ref(xrdata,t_index)\n",
    "    t_step = str(ncgrid['time'][t_index].values)\n",
    "\n",
    "    \n",
    "    fname = \"/Users/kelcy/Downloads/10m_cultural/10m_cultural/ne_10m_admin_1_states_provinces_lines.shp\"\n",
    "    # Plot\n",
    "    #fig.clear()\n",
    "    latlon_proj = ccrs.PlateCarree()\n",
    "    cs_attrs = ncgrid['ProjectionCoordinateSystem'][0].attrs\n",
    "    if cs_attrs['grid_mapping_name'] == 'azimuthal_equidistant':\n",
    "        grid_proj = ccrs.AzimuthalEquidistant(central_latitude=cs_attrs['latitude_of_projection_origin'],\n",
    "                central_longitude=cs_attrs['longitude_of_projection_origin'],\n",
    "                false_easting=cs_attrs['false_easting'],\n",
    "                false_northing=cs_attrs['false_northing'],)\n",
    "    projection=grid_proj\n",
    "    axes_class = (GeoAxes,\n",
    "                  dict(map_projection=projection))\n",
    "    axs = AxesGrid(fig, 111, axes_class=axes_class,\n",
    "                nrows_ncols=(1, 1),\n",
    "                axes_pad=0.4,\n",
    "                cbar_location='right',\n",
    "                cbar_mode='each',\n",
    "                cbar_pad=0.4,\n",
    "                cbar_size='3%',\n",
    "                label_mode='')  # note the empty label_mode\n",
    "    for ax in axs:\n",
    "        ax.coastlines()\n",
    "        shape_feature = ShapelyFeature(Reader(fname).geometries(),\n",
    "                                ccrs.PlateCarree(), edgecolor='black')\n",
    "        ax.add_feature(shape_feature, facecolor='none')\n",
    "        ax.add_feature(cartopy.feature.STATES, edgecolor = 'black')\n",
    "        ax.set_extent((hsv_ctr_lon-2.5, hsv_ctr_lon+2.5,\n",
    "                    hsv_ctr_lat-3.0, hsv_ctr_lat+2.5))\n",
    "\n",
    "        \n",
    "        gl = ax.gridlines(draw_labels=True)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "    \n",
    "    # Gridded background\n",
    "    grid_extent = (ncgrid.x.min(), ncgrid.x.max(),\n",
    "                   ncgrid.y.min(), ncgrid.y.max())\n",
    "    \n",
    "    #fig.suptitle((t_step[0:19] + ' 40 dbz, long tracks, ISO_THRESH = 12'), fontsize = 12,y=0.76)\n",
    "\n",
    "\n",
    "    # Cell ID\n",
    "    im = axs[0].imshow(refl,origin = 'lower', vmin=-25, vmax=85, cmap='pyart_LangRainbow12',extent = grid_extent, transform = grid_proj)\n",
    "    axs[0].set_title((t_step[0:19]+' ' + str(dbz)+' dbz, Tobac'))\n",
    "    axs.cbar_axes[0].colorbar(im)\n",
    "\n",
    "    track_cell = track.groupby('cell')\n",
    "    times = np.unique(track['time'])\n",
    "    track_time = track.groupby('time')\n",
    "\n",
    "    i = np.where(mask['segmentation_mask'][t_index,:,:] > 0)\n",
    "    y1, x1 = nclon[i[0],i[1]],nclat[i[0],i[1]]\n",
    "#             axs[0].plot(y1,x1, marker = '.',color = 'gray',\n",
    "#                     alpha = 0.05,linestyle='dashed',transform=latlon_proj,linewidth=1, markersize=1)\n",
    "    axs[0].scatter(y1,x1, s = 0.1,c = 'gray', marker = '.',alpha = 0.2, transform = latlon_proj)\n",
    "\n",
    "    t_step = pd.to_datetime(ncgrid['time'][t_index].data)\n",
    "    t_step =  t_step.floor(freq='min')\n",
    "\n",
    "    for i in np.unique(track['cell']):\n",
    "\n",
    "        if math.isfinite(i):\n",
    "\n",
    "            track_i = np.where(track['cell'] == i)\n",
    "\n",
    "            times = pd.to_datetime(track['time'][track_i].data)\n",
    "            times = times.floor(freq = 'min')\n",
    "\n",
    "            if np.any(times == t_step):\n",
    "                track_i = np.array(track_i)\n",
    "                track_i = np.squeeze(track_i)\n",
    "                track_i = track_i.astype(int)\n",
    "                axs[0].plot(lons[track_i], lats[track_i], '-.',\n",
    "                        color='r',markersize = 1,transform = latlon_proj)\n",
    "                axs[0].text(lons[track_i][-1],lats[track_i][-1], f'Tr {int(i)}',transform = latlon_proj,rotation=90,fontsize=8)\n",
    "        else:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202eef6-a6e1-45a8-93fc-ec501d62fbdb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(nc_grid.time)):\n",
    "#i = 5\n",
    "    time_index = i\n",
    "\n",
    "    time_step = str(nc_grid['time'][time_index].values)\n",
    "\n",
    "    fig = plt.figure(figsize=(9,9))\n",
    "    fig.set_canvas(plt.gcf().canvas)\n",
    "    plot(time_index,data,maxrefl,Features, refl_mask,Track,nc_grid,15,longitude,latitude,nc_lons,nc_lats)\n",
    "    fig.savefig('20220604_tobac_15dbz_tracks'+str(time_index)+'_KHGX.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22cd40b-6440-4c65-bf5d-7515fb58b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = []\n",
    "mean_feature_size = []\n",
    "max_feature_size = []\n",
    "for i in range(len(nc_grid.time)):\n",
    "    num_features.append(len(np.unique(refl_mask['segmentation_mask'][i,:,:])))\n",
    "    j = np.where(Features.frame == i)\n",
    "    if len(j[0]) == 0:\n",
    "        mean_feature_size.append(0)\n",
    "        max_feature_size.append(0)\n",
    "    else:\n",
    "        mean_feature_size.append(np.nanmean(Features.areas[j]))\n",
    "        max_feature_size.append(np.nanmax(Features.areas[j]))\n",
    "\n",
    "        \n",
    "cell_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f7542-9e4a-46cc-be5a-06bf78471448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "422px",
    "left": "744px",
    "right": "20px",
    "top": "113.00199127197266px",
    "width": "594px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
